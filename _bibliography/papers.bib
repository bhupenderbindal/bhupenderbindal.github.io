---
---

@string{aps = {American Physical Society,}}

@book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

@article{einstein1950meaning,
  abbr={AJP},
  bibtex_show={true},
  title={The meaning of relativity},
  author={Einstein, Albert and Taub, AH},
  journal={American Journal of Physics},
  volume={18},
  number={6},
  pages={403--404},
  year={1950},
  publisher={American Association of Physics Teachers}
}

@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein, A. and Podolsky, B. and Rosen, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  selected={true}
}

@article{einstein1905molekularkinetischen,
  title={{\"U}ber die von der molekularkinetischen Theorie der W{\"a}rme geforderte Bewegung von in ruhenden Fl{\"u}ssigkeiten suspendierten Teilchen},
  author={Einstein, A.},
  journal={Annalen der physik},
  volume={322},
  number={8},
  pages={549--560},
  year={1905},
  publisher={Wiley Online Library}
}

@article{einstein1905movement,
  abbr={Ann. Phys.},
  title={Un the movement of small particles suspended in statiunary liquids required by the molecular-kinetic theory 0f heat},
  author={Einstein, A.},
  journal={Ann. Phys.},
  volume={17},
  pages={549--560},
  year={1905}
}

@article{einstein1905electrodynamics,
  title={On the electrodynamics of moving bodies},
  author={Einstein, A.},
  year={1905}
}

@book{przibram1967letters,
  bibtex_show={true},
  title={Letters on wave mechanics},
  author={Einstein, Albert and Schrödinger, Erwin and Planck, Max and Lorentz, Hendrik Antoon and Przibram, Karl},
  year={1967},
  publisher={Vision},
  preview={wave-mechanics.gif}
}

@article{lisa,
  author          = {Lisa Mueller},
  title           = {Example: Why this article does not exist},
  journal         = {Super popular journal},
  volume          = {3},
  number          = {1},
  year            = {2020}
}



@misc{arp_dos_2021,
	title = {Dos and Don'ts of Machine Learning in Computer Security},
	url = {http://arxiv.org/abs/2010.09470},
	doi = {10.48550/arXiv.2010.09470},
	abstract = {With the growing processing power of computing systems and the increasing availability of massive datasets, machine learning algorithms have led to major breakthroughs in many different areas. This development has influenced computer security, spawning a series of work on learning-based security systems, such as for malware detection, vulnerability discovery, and binary code analysis. Despite great potential, machine learning in security is prone to subtle pitfalls that undermine its performance and render learning-based systems potentially unsuitable for security tasks and practical deployment. In this paper, we look at this problem with critical eyes. First, we identify common pitfalls in the design, implementation, and evaluation of learning-based security systems. We conduct a study of 30 papers from top-tier security conferences within the past 10 years, confirming that these pitfalls are widespread in the current security literature. In an empirical analysis, we further demonstrate how individual pitfalls can lead to unrealistic performance and interpretations, obstructing the understanding of the security problem at hand. As a remedy, we propose actionable recommendations to support researchers in avoiding or mitigating the pitfalls where possible. Furthermore, we identify open problems when applying machine learning in security and provide directions for further research.},
	number = {{arXiv}:2010.09470},
	publisher = {{arXiv}},
	author = {Arp, Daniel and Quiring, Erwin and Pendlebury, Feargus and Warnecke, Alexander and Pierazzi, Fabio and Wressnegger, Christian and Cavallaro, Lorenzo and Rieck, Konrad},
	urldate = {2023-05-30},
	date = {2021-11-30},
	eprinttype = {arxiv},
	eprint = {2010.09470 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/bhupender/Zotero/storage/24VJI2H3/Arp et al. - 2021 - Dos and Don'ts of Machine Learning in Computer Sec.pdf:application/pdf;arXiv.org Snapshot:/home/bhupender/Zotero/storage/N469AVD2/2010.html:text/html},
}

@article{shorten_survey_2019,
	title = {A survey on Image Data Augmentation for Deep Learning},
	volume = {6},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-019-0197-0},
	doi = {10.1186/s40537-019-0197-0},
	abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on {GANs} are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
	pages = {60},
	number = {1},
	journaltitle = {Journal of Big Data},
	shortjournal = {Journal of Big Data},
	author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
	urldate = {2023-05-30},
	date = {2019-07-06},
	keywords = {Big data, Data Augmentation, Deep Learning, {GANs}, Image data},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/S8EKEICN/Shorten and Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf:application/pdf;Snapshot:/home/bhupender/Zotero/storage/A5FMK8K4/s40537-019-0197-0.html:text/html},
}

@misc{he_deep_2015,
	title = {Deep Residual Learning for Image Recognition},
	url = {http://arxiv.org/abs/1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the {ImageNet} dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than {VGG} nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the {ImageNet} test set. This result won the 1st place on the {ILSVRC} 2015 classification task. We also present analysis on {CIFAR}-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the {COCO} object detection dataset. Deep residual nets are foundations of our submissions to {ILSVRC} \& {COCO} 2015 competitions, where we also won the 1st places on the tasks of {ImageNet} detection, {ImageNet} localization, {COCO} detection, and {COCO} segmentation.},
	number = {{arXiv}:1512.03385},
	publisher = {{arXiv}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2023-05-21},
	date = {2015-12-10},
	eprinttype = {arxiv},
	eprint = {1512.03385 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, notion},
	file = {arXiv.org Snapshot:/home/bhupender/Zotero/storage/5CI8S3NH/1512.html:text/html;Full Text PDF:/home/bhupender/Zotero/storage/QQJSM6KM/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf},
}

@online{noauthor_papers_nodate,
	title = {Papers with Code - Anisotropic 3D Multi-Stream {CNN} for Accurate Prostate Segmentation from Multi-Planar {MRI}},
	url = {https://paperswithcode.com/paper/anisotropic-3d-multi-stream-cnn-for-accurate},
	abstract = {Implemented in one code library.},
	urldate = {2023-04-20},
	langid = {english},
	keywords = {notion},
	file = {Snapshot:/home/bhupender/Zotero/storage/QRLFC3GG/anisotropic-3d-multi-stream-cnn-for-accurate.html:text/html},
}

@article{barbosa_learning-based_nodate,
	title = {{LEARNING}-{BASED} {CROP} {MANAGEMENT} {OPTIMIZATION} {USING} {MULTI}-{STREAM} {CONVOLUTIONAL} {NEURAL} {NETWORKS}},
	author = {Barbosa, Alexandre},
	langid = {english},
	keywords = {notion},
	file = {Barbosa - LEARNING-BASED CROP MANAGEMENT OPTIMIZATION USING .pdf:/home/bhupender/Zotero/storage/DMAAUESE/Barbosa - LEARNING-BASED CROP MANAGEMENT OPTIMIZATION USING .pdf:application/pdf},
}

@inproceedings{barbosa_multi-stream_2020,
	title = {Multi-Stream {CNN} for Spatial Resource Allocation: a Crop Management Application},
	doi = {10.1109/CVPRW50498.2020.00037},
	shorttitle = {Multi-Stream {CNN} for Spatial Resource Allocation},
	abstract = {Modeling the spatial structure of crop inputs is of great importance for accurate yield prediction. It is a fundamental step towards optimizing the spatial allocation of resources such as seed and fertilizer. We propose two distinct architectures of Multi-Stream Convolutional Neural Network ({MSCNN}) - Late Fusion ({LF}) and Early Fusion ({EF}) - to model yield response to seed and nutrient management. A study presents a comparison between proposed models with conventional 2D and 3D {CNN} architectures, and existing agronomy methods. The dataset used to train and test the models is constructed using on-farm experiment data from nine cornfields across the {US} together with multispectral satellite images. Results show that the {MSCNN}-{LF} achieved a 20\% reduction of the prediction's mean squared error value when compared to a 3D {CNN}, and a 26\% reduction when compared to a 2D {CNN}. An optimization algorithm uses the {MSCNN}-{LF} model's gradient to change the manageable inputs variables in a way the expected profit is maximized subject to resource constraints. It is shown that an increase of up to 5.2\% on expected crop yield return is obtained when compared to usual management practices.},
	eventtitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	pages = {258--266},
	booktitle = {2020 {IEEE}/{CVF} Conference on Computer Vision and Pattern Recognition Workshops ({CVPRW})},
	author = {Barbosa, Alexandre and Marinho, Thiago and Martin, Nicolas and Hovakimyan, Naira},
	date = {2020-06},
	note = {{ISSN}: 2160-7516},
	keywords = {notion, Agriculture, Analytical models, Computer architecture, Data models, Nitrogen, Soil, Three-dimensional displays},
	file = {IEEE Xplore Abstract Record:/home/bhupender/Zotero/storage/BYYJ537E/references.html:text/html;IEEE Xplore Full Text PDF:/home/bhupender/Zotero/storage/3UXEDNZP/Barbosa et al. - 2020 - Multi-Stream CNN for Spatial Resource Allocation .pdf:application/pdf},
}

@article{yamashita_convolutional_2018,
	title = {Convolutional neural networks: an overview and application in radiology},
	volume = {9},
	rights = {2018 The Author(s)},
	issn = {1869-4101},
	url = {https://insightsimaging.springeropen.com/articles/10.1007/s13244-018-0639-9},
	doi = {10.1007/s13244-018-0639-9},
	shorttitle = {Convolutional neural networks},
	abstract = {Convolutional neural network ({CNN}), a class of artificial neural networks that has become dominant in various computer vision tasks, is attracting interest across a variety of domains, including radiology. {CNN} is designed to automatically and adaptively learn spatial hierarchies of features through backpropagation by using multiple building blocks, such as convolution layers, pooling layers, and fully connected layers. This review article offers a perspective on the basic concepts of {CNN} and its application to various radiological tasks, and discusses its challenges and future directions in the field of radiology. Two challenges in applying {CNN} to radiological tasks, small dataset and overfitting, will also be covered in this article, as well as techniques to minimize them. Being familiar with the concepts and advantages, as well as limitations, of {CNN} is essential to leverage its potential in diagnostic radiology, with the goal of augmenting the performance of radiologists and improving patient care. • Convolutional neural network is a class of deep learning methods which has become dominant in various computer vision tasks and is attracting interest across a variety of domains, including radiology. • Convolutional neural network is composed of multiple building blocks, such as convolution layers, pooling layers, and fully connected layers, and is designed to automatically and adaptively learn spatial hierarchies of features through a backpropagation algorithm. • Familiarity with the concepts and advantages, as well as limitations, of convolutional neural network is essential to leverage its potential to improve radiologist performance and, eventually, patient care.},
	pages = {611--629},
	number = {4},
	journaltitle = {Insights into Imaging},
	shortjournal = {Insights Imaging},
	author = {Yamashita, Rikiya and Nishio, Mizuho and Do, Richard Kinh Gian and Togashi, Kaori},
	urldate = {2023-04-19},
	date = {2018-08},
	langid = {english},
	note = {Number: 4
Publisher: {SpringerOpen}},
	keywords = {notion},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/I8XMHNJP/Yamashita et al. - 2018 - Convolutional neural networks an overview and app.pdf:application/pdf},
}

@article{lemay_improving_2022,
	title = {Improving the repeatability of deep learning models with Monte Carlo dropout},
	volume = {5},
	rights = {2022 The Author(s)},
	issn = {2398-6352},
	url = {https://www.nature.com/articles/s41746-022-00709-3},
	doi = {10.1038/s41746-022-00709-3},
	abstract = {The integration of artificial intelligence into clinical workflows requires reliable and robust models. Repeatability is a key attribute of model robustness. Ideal repeatable models output predictions without variation during independent tests carried out under similar conditions. However, slight variations, though not ideal, may be unavoidable and acceptable in practice. During model development and evaluation, much attention is given to classification performance while model repeatability is rarely assessed, leading to the development of models that are unusable in clinical practice. In this work, we evaluate the repeatability of four model types (binary classification, multi-class classification, ordinal classification, and regression) on images that were acquired from the same patient during the same visit. We study the each model’s performance on four medical image classification tasks from public and private datasets: knee osteoarthritis, cervical cancer screening, breast density estimation, and retinopathy of prematurity. Repeatability is measured and compared on {ResNet} and {DenseNet} architectures. Moreover, we assess the impact of sampling Monte Carlo dropout predictions at test time on classification performance and repeatability. Leveraging Monte Carlo predictions significantly increases repeatability, in particular at the class boundaries, for all tasks on the binary, multi-class, and ordinal models leading to an average reduction of the 95\% limits of agreement by 16\% points and of the class disagreement rate by 7\% points. The classification accuracy improves in most settings along with the repeatability. Our results suggest that beyond about 20 Monte Carlo iterations, there is no further gain in repeatability. In addition to the higher test-retest agreement, Monte Carlo predictions are better calibrated which leads to output probabilities reflecting more accurately the true likelihood of being correctly classified.},
	pages = {1--11},
	number = {1},
	journaltitle = {npj Digital Medicine},
	shortjournal = {npj Digit. Med.},
	author = {Lemay, Andreanne and Hoebel, Katharina and Bridge, Christopher P. and Befano, Brian and De Sanjosé, Silvia and Egemen, Didem and Rodriguez, Ana Cecilia and Schiffman, Mark and Campbell, John Peter and Kalpathy-Cramer, Jayashree},
	urldate = {2023-04-12},
	date = {2022-11-18},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {notion, Biomedical engineering, Medical imaging},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/NQ3Q3EML/Lemay et al. - 2022 - Improving the repeatability of deep learning model.pdf:application/pdf},
}

@misc{geras_high-resolution_2018,
	title = {High-Resolution Breast Cancer Screening with Multi-View Deep Convolutional Neural Networks},
	url = {http://arxiv.org/abs/1703.07047},
	abstract = {Advances in deep learning for natural images have prompted a surge of interest in applying similar techniques to medical images. The majority of the initial attempts focused on replacing the input of a deep convolutional neural network with a medical image, which does not take into consideration the fundamental differences between these two types of images. Specifically, fine details are necessary for detection in medical images, unlike in natural images where coarse structures matter most. This difference makes it inadequate to use the existing network architectures developed for natural images, because they work on heavily downscaled images to reduce the memory requirements. This hides details necessary to make accurate predictions. Additionally, a single exam in medical imaging often comes with a set of views which must be fused in order to reach a correct conclusion. In our work, we propose to use a multi-view deep convolutional neural network that handles a set of high-resolution medical images. We evaluate it on large-scale mammography-based breast cancer screening ({BI}-{RADS} prediction) using 886,000 images. We focus on investigating the impact of the training set size and image size on the prediction accuracy. Our results highlight that performance increases with the size of training set, and that the best performance can only be achieved using the original resolution. In the reader study, performed on a random subset of the test set, we confirmed the efficacy of our model, which achieved performance comparable to a committee of radiologists when presented with the same data.},
	number = {{arXiv}:1703.07047},
	publisher = {{arXiv}},
	author = {Geras, Krzysztof J. and Wolfson, Stacey and Shen, Yiqiu and Wu, Nan and Kim, S. Gene and Kim, Eric and Heacock, Laura and Parikh, Ujas and Moy, Linda and Cho, Kyunghyun},
	urldate = {2023-04-05},
	date = {2018-06-27},
	eprinttype = {arxiv},
	eprint = {1703.07047 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Computer Vision and Pattern Recognition, notion, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/bhupender/Zotero/storage/GW27Z39H/Geras et al. - 2018 - High-Resolution Breast Cancer Screening with Multi.pdf:application/pdf;arXiv.org Snapshot:/home/bhupender/Zotero/storage/CEGNP95Q/1703.html:text/html},
}

@misc{wu_virtual_2023,
	title = {Virtual Sparse Convolution for Multimodal 3D Object Detection},
	url = {http://arxiv.org/abs/2303.02314},
	doi = {10.48550/arXiv.2303.02314},
	abstract = {Recently, virtual/pseudo-point-based 3D object detection that seamlessly fuses {RGB} images and {LiDAR} data by depth completion has gained great attention. However, virtual points generated from an image are very dense, introducing a huge amount of redundant computation during detection. Meanwhile, noises brought by inaccurate depth completion significantly degrade detection precision. This paper proposes a fast yet effective backbone, termed {VirConvNet}, based on a new operator {VirConv} (Virtual Sparse Convolution), for virtual-point-based 3D object detection. {VirConv} consists of two key designs: (1) {StVD} (Stochastic Voxel Discard) and (2) {NRConv} (Noise-Resistant Submanifold Convolution). {StVD} alleviates the computation problem by discarding large amounts of nearby redundant voxels. {NRConv} tackles the noise problem by encoding voxel features in both 2D image and 3D {LiDAR} space. By integrating {VirConv}, we first develop an efficient pipeline {VirConv}-L based on an early fusion design. Then, we build a high-precision pipeline {VirConv}-T based on a transformed refinement scheme. Finally, we develop a semi-supervised pipeline {VirConv}-S based on a pseudo-label framework. On the {KITTI} car 3D detection test leaderboard, our {VirConv}-L achieves 85\% {AP} with a fast running speed of 56ms. Our {VirConv}-T and {VirConv}-S attains a high-precision of 86.3\% and 87.2\% {AP}, and currently rank 2nd and 1st, respectively. The code is available at https://github.com/hailanyi/{VirConv}.},
	number = {{arXiv}:2303.02314},
	publisher = {{arXiv}},
	author = {Wu, Hai and Wen, Chenglu and Shi, Shaoshuai and Li, Xin and Wang, Cheng},
	urldate = {2023-04-05},
	date = {2023-03-03},
	eprinttype = {arxiv},
	eprint = {2303.02314 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, notion},
	file = {arXiv Fulltext PDF:/home/bhupender/Zotero/storage/FQWIMLTZ/Wu et al. - 2023 - Virtual Sparse Convolution for Multimodal 3D Objec.pdf:application/pdf;arXiv.org Snapshot:/home/bhupender/Zotero/storage/ZNJN7E4M/2303.html:text/html},
}

@misc{su_multi-view_2015,
	title = {Multi-view Convolutional Neural Networks for 3D Shape Recognition},
	url = {http://arxiv.org/abs/1505.00880},
	doi = {10.48550/arXiv.1505.00880},
	abstract = {A longstanding question in computer vision concerns the representation of 3D shapes for recognition: should 3D shapes be represented with descriptors operating on their native 3D formats, such as voxel grid or polygon mesh, or can they be effectively represented with view-based descriptors? We address this question in the context of learning to recognize 3D shapes from a collection of their rendered views on 2D images. We first present a standard {CNN} architecture trained to recognize the shapes' rendered views independently of each other, and show that a 3D shape can be recognized even from a single view at an accuracy far higher than using state-of-the-art 3D shape descriptors. Recognition rates further increase when multiple views of the shapes are provided. In addition, we present a novel {CNN} architecture that combines information from multiple views of a 3D shape into a single and compact shape descriptor offering even better recognition performance. The same architecture can be applied to accurately recognize human hand-drawn sketches of shapes. We conclude that a collection of 2D views can be highly informative for 3D shape recognition and is amenable to emerging {CNN} architectures and their derivatives.},
	number = {{arXiv}:1505.00880},
	publisher = {{arXiv}},
	author = {Su, Hang and Maji, Subhransu and Kalogerakis, Evangelos and Learned-Miller, Erik},
	urldate = {2023-04-03},
	date = {2015-09-27},
	eprinttype = {arxiv},
	eprint = {1505.00880 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, notion, Computer Science - Graphics},
	file = {arXiv Fulltext PDF:/home/bhupender/Zotero/storage/94IPB29M/Su et al. - 2015 - Multi-view Convolutional Neural Networks for 3D Sh.pdf:application/pdf;arXiv.org Snapshot:/home/bhupender/Zotero/storage/9V6LH42J/1505.html:text/html},
}

@article{hain_spiresoftware_2022,
	title = {{SPIRE}—a software tool for bicontinuous phase recognition: application for plastid cubic membranes},
	volume = {188},
	issn = {0032-0889},
	url = {https://doi.org/10.1093/plphys/kiab476},
	doi = {10.1093/plphys/kiab476},
	shorttitle = {{SPIRE}—a software tool for bicontinuous phase recognition},
	abstract = {Bicontinuous membranes in cell organelles epitomize nature’s ability to create complex functional nanostructures. Like their synthetic counterparts, these membranes are characterized by continuous membrane sheets draped onto topologically complex saddle-shaped surfaces with a periodic network-like structure. Their structure sizes, (around 50–500 nm), and fluid nature make transmission electron microscopy ({TEM}) the analysis method of choice to decipher their nanostructural features. Here we present a tool, Surface Projection Image Recognition Environment ({SPIRE}), to identify bicontinuous structures from {TEM} sections through interactive identification by comparison to mathematical “nodal surface” models. The prolamellar body ({PLB}) of plant etioplasts is a bicontinuous membrane structure with a key physiological role in chloroplast biogenesis. However, the determination of its spatial structural features has been held back by the lack of tools enabling the identification and quantitative analysis of symmetric membrane conformations. Using our {SPIRE} tool, we achieved a robust identification of the bicontinuous diamond surface as the dominant {PLB} geometry in angiosperm etioplasts in contrast to earlier long-standing assertions in the literature. Our data also provide insights into membrane storage capacities of {PLBs} with different volume proportions and hint at the limited role of a plastid ribosome localization directly inside the {PLB} grid for its proper functioning. This represents an important step in understanding their as yet elusive structure–function relationship.},
	pages = {81--96},
	number = {1},
	journaltitle = {Plant Physiology},
	shortjournal = {Plant Physiology},
	author = {Hain, Tobias M and Bykowski, Michał and Saba, Matthias and Evans, Myfanwy E and Schröder-Turk, Gerd E and Kowalewska, Łucja},
	urldate = {2023-04-01},
	date = {2022-01-01},
	keywords = {notion},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/Q9VL72GF/Hain et al. - 2022 - SPIRE—a software tool for bicontinuous phase recog.pdf:application/pdf;Snapshot:/home/bhupender/Zotero/storage/MKDEYQ3R/6400263.html:text/html},
}

@article{rzanny_image-based_2022,
	title = {Image-Based Automated Recognition of 31 Poaceae Species: The Most Relevant Perspectives},
	volume = {12},
	issn = {1664-462X},
	url = {https://www.frontiersin.org/articles/10.3389/fpls.2021.804140},
	shorttitle = {Image-Based Automated Recognition of 31 Poaceae Species},
	abstract = {Poaceae represent one of the largest plant families in the world. Many species are of great economic importance as food and forage plants while others represent important weeds in agriculture. Although a large number of studies currently address the question of how plants can be best recognized on images, there is a lack of studies evaluating specific approaches for uniform species groups considered difficult to identify because they lack obvious visual characteristics. Poaceae represent an example of such a species group, especially when they are non-flowering. Here we present the results from an experiment to automatically identify Poaceae species based on images depicting six well-defined perspectives. One perspective shows the inflorescence while the others show vegetative parts of the plant such as the collar region with the ligule, adaxial and abaxial side of the leaf and culm nodes. For each species we collected 80 observations, each representing a series of six images taken with a smartphone camera. We extract feature representations from the images using five different convolutional neural networks ({CNN}) trained on objects from different domains and classify them using four state-of-the art classification algorithms. We combine these perspectives via score level fusion. In order to evaluate the potential of identifying non-flowering Poaceae we separately compared perspective combinations either comprising inflorescences or not. We find that for a fusion of all six perspectives, using the best combination of feature extraction {CNN} and classifier, an accuracy of 96.1\% can be achieved. Without the inflorescence, the overall accuracy is still as high as 90.3\%. In all but one case the perspective conveying the most information about the species (excluding inflorescence) is the ligule in frontal view. Our results show that even species considered very difficult to identify can achieve high accuracies in automatic identification as long as images depicting suitable perspectives are available. We suggest that our approach could be transferred to other difficult-to-distinguish species groups in order to identify the most relevant perspectives.},
	journaltitle = {Frontiers in Plant Science},
	author = {Rzanny, Michael and Wittich, Hans Christian and Mäder, Patrick and Deggelmann, Alice and Boho, David and Wäldchen, Jana},
	urldate = {2023-03-25},
	date = {2022},
	keywords = {notion},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/Q7JY9V3J/Rzanny et al. - 2022 - Image-Based Automated Recognition of 31 Poaceae Sp.pdf:application/pdf},
}

@online{noauthor_multi-view_nodate,
	title = {Multi-view classification with convolutional neural networks {\textbar} Connected Papers},
	url = {https://www.connectedpapers.com/main/dd49f60f922238fc87c34b0d158ab26e1252c9f0/Multi%20view-classification-with-convolutional-neural-networks/graph},
	urldate = {2023-03-25},
	keywords = {notion},
	file = {Multi-view classification with convolutional neural networks | Connected Papers:/home/bhupender/Zotero/storage/Y5LUY5GW/graph.html:text/html},
}

@article{seeland_multi-view_2021,
	title = {Multi-view classification with convolutional neural networks},
	volume = {16},
	issn = {1932-6203},
	url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0245230},
	doi = {10.1371/journal.pone.0245230},
	abstract = {Humans’ decision making process often relies on utilizing visual information from different views or perspectives. However, in machine-learning-based image classification we typically infer an object’s class from just a single image showing an object. Especially for challenging classification problems, the visual information conveyed by a single image may be insufficient for an accurate decision. We propose a classification scheme that relies on fusing visual information captured through images depicting the same object from multiple perspectives. Convolutional neural networks are used to extract and encode visual features from the multiple views and we propose strategies for fusing these information. More specifically, we investigate the following three strategies: (1) fusing convolutional feature maps at differing network depths; (2) fusion of bottleneck latent representations prior to classification; and (3) score fusion. We systematically evaluate these strategies on three datasets from different domains. Our findings emphasize the benefit of integrating information fusion into the network rather than performing it by post-processing of classification scores. Furthermore, we demonstrate through a case study that already trained networks can be easily extended by the best fusion strategy, outperforming other approaches by large margin.},
	pages = {e0245230},
	number = {1},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLOS} {ONE}},
	author = {Seeland, Marco and Mäder, Patrick},
	urldate = {2023-03-25},
	date = {2021-12-01},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {notion, Ants, Convolution, Crops, Flowering plants, Leaves, Neural networks, Plants, Vision},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/UXK8L3AF/Seeland and Mäder - 2021 - Multi-view classification with convolutional neura.pdf:application/pdf},
}

@article{mezzenga_nature-inspired_2019,
	title = {Nature-Inspired Design and Application of Lipidic Lyotropic Liquid Crystals},
	volume = {31},
	rights = {© 2019 {WILEY}-{VCH} Verlag {GmbH} \& Co. {KGaA}, Weinheim},
	issn = {1521-4095},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/adma.201900818},
	doi = {10.1002/adma.201900818},
	abstract = {Amphiphilic lipids aggregate in aqueous solution into a variety of structural arrangements. Among the plethora of ordered structures that have been reported, many have also been observed in nature. In addition, due to their unique morphologies, the hydrophilic and hydrophobic domains, very high internal interfacial surface area, and the multitude of possible order−order transitions depending on environmental changes, very promising applications have been developed for these systems in recent years. These include crystallization in inverse bicontinuous cubic phases for membrane protein structure determination, generation of advanced materials, sustained release of bioactive molecules, and control of chemical reactions. The outstanding diverse functionalities of lyotropic liquid crystalline phases found in nature and industry are closely related to the topology, including how their nanoscopic domains are organized. This leads to notable examples of correlation between structure and macroscopic properties, which is itself central to the performance of materials in general. The physical origin of the formation of the known classes of lipidic lyotropic liquid crystalline phases, their structure, and their occurrence in nature are described, and their application in materials science and engineering, biology, medical, and pharmaceutical products, and food science and technology are exemplified.},
	pages = {1900818},
	number = {35},
	journaltitle = {Advanced Materials},
	author = {Mezzenga, Raffaele and Seddon, John M. and Drummond, Calum J. and Boyd, Ben J. and Schröder-Turk, Gerd E. and Sagalowicz, Laurent},
	urldate = {2023-06-27},
	date = {2019},
	langid = {english},
	keywords = {bicontinous cubic phases, lipid self-assembly, lipidic mesophases, liquid crystals, nanoconfinement},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/BHRAGQWI/Mezzenga et al. - 2019 - Nature-Inspired Design and Application of Lipidic .pdf:application/pdf;Snapshot:/home/bhupender/Zotero/storage/5NR4GWXH/adma.html:text/html},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	rights = {2015 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	urldate = {2023-06-28},
	date = {2015-05},
	langid = {english},
	note = {Number: 7553
Publisher: Nature Publishing Group},
	keywords = {Computer science, Mathematics and computing},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/H3EGXPRB/LeCun et al. - 2015 - Deep learning.pdf:application/pdf},
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	issn = {1558-2256},
	doi = {10.1109/5.726791},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks ({GTN}), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	pages = {2278--2324},
	number = {11},
	journaltitle = {Proceedings of the {IEEE}},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	date = {1998-11},
	note = {Conference Name: Proceedings of the {IEEE}},
	keywords = {Neural networks, Character recognition, Feature extraction, Hidden Markov models, Machine learning, Multi-layer neural network, Optical character recognition software, Optical computing, Pattern recognition, Principal component analysis},
	file = {IEEE Xplore Abstract Record:/home/bhupender/Zotero/storage/G9TS6A75/726791.html:text/html;IEEE Xplore Full Text PDF:/home/bhupender/Zotero/storage/S3MYCDL2/Lecun et al. - 1998 - Gradient-based learning applied to document recogn.pdf:application/pdf},
}

@online{noauthor_stereological_nodate,
	title = {stereological meaning - Google Search},
	url = {https://www.google.com/search?q=stereological+meaning&oq=stereological+meani&aqs=chrome.1.69i57j0i13i19i512j0i15i19i22i30l2j0i19i22i30l2j0i15i19i22i30.3525j0j7&client=ubuntu-chr&sourceid=chrome&ie=UTF-8},
	urldate = {2023-06-28},
}

@misc{he_deep_2015-1,
	title = {Deep Residual Learning for Image Recognition},
	url = {http://arxiv.org/abs/1512.03385},
	doi = {10.48550/arXiv.1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the {ImageNet} dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than {VGG} nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the {ImageNet} test set. This result won the 1st place on the {ILSVRC} 2015 classification task. We also present analysis on {CIFAR}-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the {COCO} object detection dataset. Deep residual nets are foundations of our submissions to {ILSVRC} \& {COCO} 2015 competitions, where we also won the 1st places on the tasks of {ImageNet} detection, {ImageNet} localization, {COCO} detection, and {COCO} segmentation.},
	number = {{arXiv}:1512.03385},
	publisher = {{arXiv}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2023-06-28},
	date = {2015-12-10},
	eprinttype = {arxiv},
	eprint = {1512.03385 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/home/bhupender/Zotero/storage/B5TMYZ6P/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf;arXiv.org Snapshot:/home/bhupender/Zotero/storage/ISMSG2TK/1512.html:text/html},
}

@misc{arp_dos_2021-1,
	title = {Dos and Don'ts of Machine Learning in Computer Security},
	url = {http://arxiv.org/abs/2010.09470},
	doi = {10.48550/arXiv.2010.09470},
	abstract = {With the growing processing power of computing systems and the increasing availability of massive datasets, machine learning algorithms have led to major breakthroughs in many different areas. This development has influenced computer security, spawning a series of work on learning-based security systems, such as for malware detection, vulnerability discovery, and binary code analysis. Despite great potential, machine learning in security is prone to subtle pitfalls that undermine its performance and render learning-based systems potentially unsuitable for security tasks and practical deployment. In this paper, we look at this problem with critical eyes. First, we identify common pitfalls in the design, implementation, and evaluation of learning-based security systems. We conduct a study of 30 papers from top-tier security conferences within the past 10 years, confirming that these pitfalls are widespread in the current security literature. In an empirical analysis, we further demonstrate how individual pitfalls can lead to unrealistic performance and interpretations, obstructing the understanding of the security problem at hand. As a remedy, we propose actionable recommendations to support researchers in avoiding or mitigating the pitfalls where possible. Furthermore, we identify open problems when applying machine learning in security and provide directions for further research.},
	number = {{arXiv}:2010.09470},
	publisher = {{arXiv}},
	author = {Arp, Daniel and Quiring, Erwin and Pendlebury, Feargus and Warnecke, Alexander and Pierazzi, Fabio and Wressnegger, Christian and Cavallaro, Lorenzo and Rieck, Konrad},
	urldate = {2023-07-06},
	date = {2021-11-30},
	eprinttype = {arxiv},
	eprint = {2010.09470 [cs]},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/home/bhupender/Zotero/storage/N7FC5ZTI/Arp et al. - 2021 - Dos and Don'ts of Machine Learning in Computer Sec.pdf:application/pdf;arXiv.org Snapshot:/home/bhupender/Zotero/storage/MLXIRPKM/2010.html:text/html},
}


@book{goodfellow_deep_2016,
	title = {Deep Learning},
	isbn = {978-0-262-03561-3},
	abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of {OpenAI}; cofounder and {CEO} of Tesla and {SpaceXDeep} learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
	pagetotal = {801},
	publisher = {{MIT} Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	date = {2016-11-18},
	langid = {english},
	note = {Google-Books-{ID}: Np9SDQAAQBAJ},
	keywords = {Computers / Artificial Intelligence / General, Computers / Computer Science},
}



@incollection{wessels_computational_2022,
	title = {Computational Homogenization Using Convolutional Neural Networks},
	isbn = {978-3-030-87311-0},
	abstract = {The classic tasks of computational engineers are to investigate and optimize structures in terms of their mechanical behavior. This iterative process usually requires a large number of calculations of different macroscopic structures of the same material. The computational time in this design-loop directly affects the time to market. Depending on the model complexity, describing the interaction between micro- and macro-scale can be computationally expensive and even prohibitive for engineering practice. This holds especially true if the physics on the micro-scale is complex involving inelastic behavior, fracture and/or phase change. In this paper, recent trends in Scientific Machine Learning ({SciML}), which may advance computational homogenization in the sense of the digital twin paradigm, are reviewed. We believe that {SciML} techniques for computational homogenization will make micro-macro simulations become applicable at low extra cost in engineering practice. This work is partially funded by the {DFG} Priority Program {SPP} 2020 Experimental-Virtual-Lab and the {DFG} Collaborative Research Center {SFB} 1153 Tailored Forming.},
	pages = {569--579},
	author = {Wessels, Henning and Böhm, Christoph and Aldakheel, Fadi and Hüpgen, Markus and Haist, Michael and Lohaus, Ludger and Wriggers, Peter},
	date = {2022-01-01},
	doi = {10.1007/978-3-030-87312-7_55},
}


@book{chollet_deep_2021,
	location = {Shelter Island, {NY}},
	edition = {Second edition},
	title = {Deep learning with Python},
	isbn = {978-1-63835-009-5},
	url = {https://search.ebscohost.com/login.aspx?direct=true&scope=site&db=nlebk&db=nlabk&AN=3073023},
	abstract = {Deep Learning with Python, Second Edition introduces the field of deep learning using Python and the powerful Keras library. In this revised and expanded new edition, Keras creator François Chollet offers insights for both novice and experienced machine learning practitioners. As you move through this book, you'll build your understanding through intuitive explanations, crisp illustrations, and clear examples. You'll quickly pick up the skills you need to start developing deep-learning applications},
	pagetotal = {504},
	publisher = {Manning Publications Co.},
	author = {Chollet, François},
	urldate = {2023-07-08},
	date = {2021},
	note = {{OCLC}: 1296760900},
	keywords = {Apprentissage automatique, Electronic books, Machine learning, Neural networks (Computer science), Neural Networks, Computer, Python (Computer program language), Python (Langage de programmation), Réseaux neuronaux (Informatique)},
}


@article{yagis_effect_2021,
	title = {Effect of data leakage in brain {MRI} classification using 2D convolutional neural networks},
	volume = {11},
	rights = {2021 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-01681-w},
	doi = {10.1038/s41598-021-01681-w},
	abstract = {In recent years, 2D convolutional neural networks ({CNNs}) have been extensively used to diagnose neurological diseases from magnetic resonance imaging ({MRI}) data due to their potential to discern subtle and intricate patterns. Despite the high performances reported in numerous studies, developing {CNN} models with good generalization abilities is still a challenging task due to possible data leakage introduced during cross-validation ({CV}). In this study, we quantitatively assessed the effect of a data leakage caused by 3D {MRI} data splitting based on a 2D slice-level using three 2D {CNN} models to classify patients with Alzheimer’s disease ({AD}) and Parkinson’s disease ({PD}). Our experiments showed that slice-level {CV} erroneously boosted the average slice level accuracy on the test set by 30\% on Open Access Series of Imaging Studies ({OASIS}), 29\% on Alzheimer’s Disease Neuroimaging Initiative ({ADNI}), 48\% on Parkinson’s Progression Markers Initiative ({PPMI}) and 55\% on a local de-novo {PD} Versilia dataset. Further tests on a randomly labeled {OASIS}-derived dataset produced about 96\% of (erroneous) accuracy (slice-level split) and 50\% accuracy (subject-level split), as expected from a randomized experiment. Overall, the extent of the effect of an erroneous slice-based {CV} is severe, especially for small datasets.},
	pages = {22544},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Yagis, Ekin and Atnafu, Selamawet Workalemahu and García Seco de Herrera, Alba and Marzi, Chiara and Scheda, Riccardo and Giannelli, Marco and Tessa, Carlo and Citi, Luca and Diciotti, Stefano},
	urldate = {2023-07-11},
	date = {2021-11-19},
	langid = {english},
	note = {Number: 1
Publisher: Nature Publishing Group},
	keywords = {Biomedical engineering, Neurodegenerative diseases},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/XC4HYIH2/Yagis et al. - 2021 - Effect of data leakage in brain MRI classification.pdf:application/pdf},
}



@article{dolata_double-stream_2017,
	title = {Double-stream Convolutional Neural Networks for Machine Vision Inspection of Natural Products},
	volume = {31},
	issn = {0883-9514},
	url = {https://doi.org/10.1080/08839514.2018.1428491},
	doi = {10.1080/08839514.2018.1428491},
	abstract = {There are known applications of convolutional neural networks to vision inspection of natural products. For many products it is sufficient to acquire and process a single image, but some might require imaging from two sides. Human experts performing quality inspection of malting barley typically only observe one side of each grain, but in doubtful cases look at both sides, intrinsically combining the information. In this paper, we make two contributions. We present a method for determining whether imaging objects from two sides yields performance benefits over single-sided imaging. Then we introduce a double-stream convolutional network for reasoning from two images simultaneously and analyze several methods of combining information from two streams. We find that when orientation of the object is unpredictable and the streams are not specialized to process a particular view, a fully shared architecture combining information on the prediction level yields best performance (98.7\% accuracy on our dataset).},
	pages = {643--659},
	number = {7},
	journaltitle = {Applied Artificial Intelligence},
	author = {Dolata, Przemysław and Mrzygłód, Mariusz and Reiner, Jacek},
	urldate = {2023-07-20},
	date = {2017-09-14},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/08839514.2018.1428491},
	keywords = {Convolutional neural networks, information fusion, machine vision, natural products},
	file = {Full Text PDF:/home/bhupender/Zotero/storage/72DDDXPI/Dolata et al. - 2017 - Double-stream Convolutional Neural Networks for Ma.pdf:application/pdf},
}

@article{setio_pulmonary_2016,
	title = {Pulmonary Nodule Detection in {CT} Images: False Positive Reduction Using Multi-View Convolutional Networks},
	volume = {35},
	issn = {1558-254X},
	doi = {10.1109/TMI.2016.2536809},
	shorttitle = {Pulmonary Nodule Detection in {CT} Images},
	abstract = {We propose a novel Computer-Aided Detection ({CAD}) system for pulmonary nodules using multi-view convolutional networks ({ConvNets}), for which discriminative features are automatically learnt from the training data. The network is fed with nodule candidates obtained by combining three candidate detectors specifically designed for solid, subsolid, and large nodules. For each candidate, a set of 2-D patches from differently oriented planes is extracted. The proposed architecture comprises multiple streams of 2-D {ConvNets}, for which the outputs are combined using a dedicated fusion method to get the final classification. Data augmentation and dropout are applied to avoid overfitting. On 888 scans of the publicly available {LIDC}-{IDRI} dataset, our method reaches high detection sensitivities of 85.4\% and 90.1\% at 1 and 4 false positives per scan, respectively. An additional evaluation on independent datasets from the {ANODE}09 challenge and {DLCST} is performed. We showed that the proposed multi-view {ConvNets} is highly suited to be used for false positive reduction of a {CAD} system.},
	pages = {1160--1169},
	number = {5},
	journaltitle = {{IEEE} Transactions on Medical Imaging},
	author = {Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Litjens, Geert and Gerke, Paul and Jacobs, Colin and van Riel, Sarah J. and Wille, Mathilde Marie Winkler and Naqibullah, Matiullah and Sánchez, Clara I. and van Ginneken, Bram},
	date = {2016-05},
	note = {Conference Name: {IEEE} Transactions on Medical Imaging},
	keywords = {Cancer, Computed tomography, computer-aided detection, convolutional networks, deep learning, Design automation, Feature extraction, Lesions, lung cancer, Lungs, pulmonary nodule, Solids},
	file = {IEEE Xplore Full Text PDF:/home/bhupender/Zotero/storage/63RDLJR6/Setio et al. - 2016 - Pulmonary Nodule Detection in CT Images False Pos.pdf:application/pdf},
}


@misc{zhang_understanding_2017,
	title = {Understanding deep learning requires rethinking generalization},
	url = {http://arxiv.org/abs/1611.03530},
	abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
	number = {{arXiv}:1611.03530},
	publisher = {{arXiv}},
	author = {Zhang, Chiyuan and Bengio, Samy and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol},
	urldate = {2023-07-31},
	date = {2017-02-26},
	eprinttype = {arxiv},
	eprint = {1611.03530 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/home/bhupender/Zotero/storage/ZFXNW9WI/1611.html:text/html;Full Text PDF:/home/bhupender/Zotero/storage/8K9G9XIF/Zhang et al. - 2017 - Understanding deep learning requires rethinking ge.pdf:application/pdf},
}


@inreference{noauthor_etioplast_2023,
	title = {Etioplast},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {https://en.wikipedia.org/w/index.php?title=Etioplast&oldid=1131257961},
	abstract = {Etioplasts are an intermediate type of plastid that develop from proplastids that have not been exposed to light, and convert into chloroplasts upon exposure to light. They are usually found in stem and leaf tissue of flowering plants (Angiosperms) grown either in complete darkness, or in extremely low-light conditions.},
	booktitle = {Wikipedia},
	urldate = {2023-08-06},
	date = {2023-01-03},
	langid = {english},
	note = {Page Version {ID}: 1131257961},
	file = {Snapshot:/home/bhupender/Zotero/storage/CHU9GIU8/Etioplast.html:text/html},
}